{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform Analysis Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a function for mass data addition (all the unique EDF files). I'll merge them into a single table for easy analysis. Waves are waves-- so long as they have the same filtering and they're all originally raw EEG! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's a major problem with unreliable annotations, I'm taking matters into my own hands and manually constructing a label list for fixed 30s intervals. I'll do this by binning annotations from the paired Hypnogram for each file. \n",
    "- Going to time-align the labels using `raw.annotations` \n",
    "- Then slice the entire sleep period into 30s chunks \n",
    "- Finally, assign the sleep stage based on the label-list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne \n",
    "from mne.time_frequency import psd_array_welch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def process_edf_pair(psg_path, hypnogram_path): \n",
    "    '''\n",
    "    Loads EDF EEG recording and corresponding hypnogram \n",
    "    Extracts 30s epochs, labels them, and returns a features df\n",
    "\n",
    "    Returns: \n",
    "        features (pd.DataFrame): Features + newly created 'label' col (sleep stage as str)\n",
    "    '''\n",
    "\n",
    "    raw = mne.io.read_raw_edf(psg_path, preload=True) \n",
    "    raw.set_annotations(mne.read_annotations(hypnogram_path))\n",
    "    raw.pick(['EEG Fpz-Cz']) \n",
    "\n",
    "    data = raw.get_data()[0]\n",
    "    sfreq = raw.info['sfreq']\n",
    "    total_duration = int(data.shape[-1] / sfreq) # in seconds!\n",
    "\n",
    "    # Map annotation label -> clean stage name\n",
    "    stage_map = {\n",
    "        'Sleep stage W': 'Wake',\n",
    "        'Sleep stage 1': 'N1',\n",
    "        'Sleep stage 2': 'N2',\n",
    "        'Sleep stage 3': 'N3',\n",
    "        'Sleep stage 4': 'N3', # Mergnig 4 into N3\n",
    "        'Sleep stage R': 'REM'\n",
    "    }\n",
    "\n",
    "    epoch_length = 30 # seconds\n",
    "    n_epochs = total_duration // epoch_length\n",
    "    labels = ['UNKNOWN'] * n_epochs\n",
    "\n",
    "    for ann in raw.annotations:\n",
    "        label = stage_map.get(ann['description'], None)\n",
    "        if label is None: \n",
    "            continue\n",
    "        start = int(ann['onset']) // epoch_length\n",
    "        duration = int(ann['duration']) // epoch_length\n",
    "\n",
    "        for i in range(start, min(start + duration, n_epochs)):\n",
    "            labels[i] = label\n",
    "\n",
    "    # Remove unknown-labeled epochs\n",
    "    valid_idxs = [i for i, l in enumerate(labels) if l != 'UNKNOWN'] \n",
    "\n",
    "    # Manually epoch the signal into 30s chunks \n",
    "    samples_per_epoch = int(epoch_length * sfreq) \n",
    "    epoch_data = np.array([\n",
    "        data[i * samples_per_epoch:(i+1) * samples_per_epoch]\n",
    "        for i in valid_idxs if (i+1) * samples_per_epoch <= len(data) \n",
    "    ])\n",
    "        \n",
    "    # Compute bandpower features \n",
    "    psds, freqs = psd_array_welch(epoch_data[:, np.newaxis, :], sfreq=sfreq, fmin=0.5, fmax=40, n_fft=256)\n",
    "\n",
    "    features = pd.DataFrame({\n",
    "        'delta': bandpower(psds, freqs, (0.5, 4)),\n",
    "        'theta': bandpower(psds, freqs, (4, 8)),\n",
    "        'alpha': bandpower(psds, freqs, (8, 13)),\n",
    "        'beta':  bandpower(psds, freqs, (13, 30)),\n",
    "        'label': [labels[i] for i in valid_idxs]\n",
    "    })\n",
    "\n",
    "    # Adding subject ID derived from filename (ex. \"ST7011J\") \n",
    "    subj_id = os.path.basename(psg_path)[2:6]\n",
    "    features['subject_id'] = subj_id\n",
    "\n",
    "    return features\n",
    "\n",
    "def bandpower(psds, freqs, band):\n",
    "    '''\n",
    "    Small hepler for process_edf_pair\n",
    "    Returns mean band power in specified frequency band\n",
    "    '''\n",
    "    idx = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    return psds[:, :, idx].mean(axis=-1).mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Loop over all .edf files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Match PSG and Hypnogram files by prefix\n",
    "data_dir = '../data/sleep_waves/'\n",
    "files = os.listdir(data_dir) \n",
    "\n",
    "# Grouping PSG and Hypnogram files by shared sybject root (first 7 chars) \n",
    "psg_files = [f for f in files if f.endswith('-PSG.edf')]\n",
    "hyp_files = [f for f in files if 'Hypnogram' in f] \n",
    "\n",
    "file_pairs = []\n",
    "\n",
    "for psg in psg_files:\n",
    "    subj_root = psg[:7] # example: 'ST7011J'\n",
    "    matching_hyp = [h for h in hyp_files if h.startswith(subj_root)]\n",
    "\n",
    "    if matching_hyp: \n",
    "        psg_path = os.path.join(data_dir, psg) \n",
    "        hyp_path = os.path.join(data_dir, matching_hyp[0]) # Note: assuming only 1 match! \n",
    "        file_pairs.append((psg_path, hyp_path)) \n",
    "    else: \n",
    "        print(f'No matching hypnogram for {psg}')\n",
    "\n",
    "print(f'Found {len(file_pairs)} valid PSG-Hypnogram edf pairs') \n",
    "\n",
    "# Process all and concat \n",
    "all_feats = []\n",
    "\n",
    "for psg, hyp in file_pairs:\n",
    "    print(f\"üß™ Processing: {os.path.basename(psg)} & {os.path.basename(hyp)}\")\n",
    "    try: \n",
    "        features = process_edf_pair(psg, hyp)\n",
    "        all_feats.append(features) \n",
    "        print(f'\\n‚úÖ Processed: {os.path.basename(psg)}:{len(features)} epochs\\n')\n",
    "    except Exception as e: \n",
    "        print(f'‚ùå Failed on {psg}: {e}')\n",
    "\n",
    "df_edf = pd.concat(all_feats, ignore_index=True) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Distinguish Between Subjects? \n",
    "Sleep progresses through ~4-5 distinct cycles per night (each 90-100 mins). Each cycle starts in N1 / Wake (still digging for this answer), and progresses to REM. We've learned that later cycles (in a typical night sleep) have less N3 and more REM.  \n",
    "  \n",
    "  Since these patterns are subject-specific, it makes sense to segmenet by subject and learn from these cycles within a given night. If we know where cycles start and end, the HMM can follow real transitions, preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new column `cycle` before model training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cycle Conditions \n",
    "- Wake --> N1 or N2 (start of sleep)\n",
    "- REM --> Wake (likely end of cycle)\n",
    "- Duration > 220 epochs (110 mins) \n",
    "\n",
    "Assigning a `cycle` column. Resets to 0 for each subject, allowing for easier cycle tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_subject_cycles(df: pd.DataFrame, min_cycle_len=60, max_cycle_len=140, min_rem_epochs=4): \n",
    "    '''\n",
    "    Segments sleep data into cycles per subject, based on sleep stage transitions\n",
    "    Assumes 30s epochs. Each cycle is marked after a qualifying REM streak\n",
    "\n",
    "    Args: \n",
    "        df: EEG data-- requires 'label' and 'subject_id' col \n",
    "        min_cycle_len (int): min expected cycle length (60 mins)\n",
    "        max_cycle_len (int): max expected cycle length (120 mins)\n",
    "        min_rem_epochs (int): min number of REM epochs to consider a valid REM phase\n",
    "\n",
    "    Returns: \n",
    "        df: original df with added 'cycle' column, segmented per subject\n",
    "    '''\n",
    "\n",
    "    df = df.copy()\n",
    "    all_segmented = []\n",
    "\n",
    "    # Epoch = 30s \n",
    "    min_len = (min_cycle_len * 2) \n",
    "    max_len = (max_cycle_len * 2) \n",
    "\n",
    "    for subject_id, subject_df in df.groupby('subject_id'): \n",
    "        labels = subject_df['label'].values\n",
    "        cycle_col = np.zeros(len(labels), dtype=int) \n",
    "\n",
    "        cycle = 0 \n",
    "        last_idx = 0 \n",
    "        rem_streak = 0\n",
    "        rem_end_idx = None\n",
    "\n",
    "        for i in range(1, len(labels)): \n",
    "            cycle_col[i] = cycle\n",
    "\n",
    "            if labels[i] == 'REM': \n",
    "                rem_streak += 1\n",
    "                rem_end_idx = i # Update while REM continues!\n",
    "            else: \n",
    "                if rem_streak >= min_rem_epochs and rem_end_idx is not None:\n",
    "                    span = np.sum(~np.isin(labels[last_idx:rem_end_idx + 1], ['Wake', 'UNKNOWN']))\n",
    "                    if min_len <= span <= max_len: \n",
    "                        cycle += 1 \n",
    "                        last_idx = rem_end_idx + 1 # Start next cycle after REM block!\n",
    "                rem_streak = 0 \n",
    "                rem_end_idx = None\n",
    "\n",
    "        subject_df = subject_df.copy()\n",
    "        subject_df['cycle'] = cycle_col \n",
    "        all_segmented.append(subject_df) \n",
    "\n",
    "    return pd.concat(all_segmented, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.160646e-12</td>\n",
       "      <td>3.309411e-12</td>\n",
       "      <td>1.943593e-12</td>\n",
       "      <td>2.366059e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.988774e-10</td>\n",
       "      <td>1.235113e-11</td>\n",
       "      <td>4.446865e-12</td>\n",
       "      <td>2.844799e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.534984e-10</td>\n",
       "      <td>2.390680e-12</td>\n",
       "      <td>1.519197e-12</td>\n",
       "      <td>5.406593e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.962507e-11</td>\n",
       "      <td>2.943184e-12</td>\n",
       "      <td>1.687577e-12</td>\n",
       "      <td>5.375286e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.378089e-11</td>\n",
       "      <td>1.779550e-12</td>\n",
       "      <td>2.156748e-12</td>\n",
       "      <td>4.648331e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42686</th>\n",
       "      <td>4.120337e-11</td>\n",
       "      <td>7.154511e-12</td>\n",
       "      <td>1.723270e-12</td>\n",
       "      <td>2.457063e-13</td>\n",
       "      <td>N2</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42687</th>\n",
       "      <td>9.937038e-11</td>\n",
       "      <td>4.455668e-12</td>\n",
       "      <td>1.793157e-12</td>\n",
       "      <td>3.096157e-13</td>\n",
       "      <td>N2</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42688</th>\n",
       "      <td>2.846232e-10</td>\n",
       "      <td>1.342760e-11</td>\n",
       "      <td>3.760796e-12</td>\n",
       "      <td>3.510913e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42689</th>\n",
       "      <td>9.707442e-10</td>\n",
       "      <td>2.485227e-11</td>\n",
       "      <td>6.117589e-12</td>\n",
       "      <td>8.264715e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42690</th>\n",
       "      <td>1.084597e-09</td>\n",
       "      <td>1.266863e-10</td>\n",
       "      <td>2.847203e-11</td>\n",
       "      <td>9.301527e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42691 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              delta         theta         alpha          beta label  \\\n",
       "0      6.160646e-12  3.309411e-12  1.943593e-12  2.366059e-12  Wake   \n",
       "1      4.988774e-10  1.235113e-11  4.446865e-12  2.844799e-12  Wake   \n",
       "2      1.534984e-10  2.390680e-12  1.519197e-12  5.406593e-13  Wake   \n",
       "3      4.962507e-11  2.943184e-12  1.687577e-12  5.375286e-13  Wake   \n",
       "4      2.378089e-11  1.779550e-12  2.156748e-12  4.648331e-13  Wake   \n",
       "...             ...           ...           ...           ...   ...   \n",
       "42686  4.120337e-11  7.154511e-12  1.723270e-12  2.457063e-13    N2   \n",
       "42687  9.937038e-11  4.455668e-12  1.793157e-12  3.096157e-13    N2   \n",
       "42688  2.846232e-10  1.342760e-11  3.760796e-12  3.510913e-12  Wake   \n",
       "42689  9.707442e-10  2.485227e-11  6.117589e-12  8.264715e-12  Wake   \n",
       "42690  1.084597e-09  1.266863e-10  2.847203e-11  9.301527e-12  Wake   \n",
       "\n",
       "      subject_id  cycle  \n",
       "0           7011      0  \n",
       "1           7011      0  \n",
       "2           7011      0  \n",
       "3           7011      0  \n",
       "4           7011      0  \n",
       "...          ...    ...  \n",
       "42686       7242      4  \n",
       "42687       7242      4  \n",
       "42688       7242      4  \n",
       "42689       7242      4  \n",
       "42690       7242      4  \n",
       "\n",
       "[42691 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edf = segment_subject_cycles(df_edf)\n",
    "df_edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.160646e-12</td>\n",
       "      <td>3.309411e-12</td>\n",
       "      <td>1.943593e-12</td>\n",
       "      <td>2.366059e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.988774e-10</td>\n",
       "      <td>1.235113e-11</td>\n",
       "      <td>4.446865e-12</td>\n",
       "      <td>2.844799e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.534984e-10</td>\n",
       "      <td>2.390680e-12</td>\n",
       "      <td>1.519197e-12</td>\n",
       "      <td>5.406593e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.962507e-11</td>\n",
       "      <td>2.943184e-12</td>\n",
       "      <td>1.687577e-12</td>\n",
       "      <td>5.375286e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.378089e-11</td>\n",
       "      <td>1.779550e-12</td>\n",
       "      <td>2.156748e-12</td>\n",
       "      <td>4.648331e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42686</th>\n",
       "      <td>4.120337e-11</td>\n",
       "      <td>7.154511e-12</td>\n",
       "      <td>1.723270e-12</td>\n",
       "      <td>2.457063e-13</td>\n",
       "      <td>N2</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42687</th>\n",
       "      <td>9.937038e-11</td>\n",
       "      <td>4.455668e-12</td>\n",
       "      <td>1.793157e-12</td>\n",
       "      <td>3.096157e-13</td>\n",
       "      <td>N2</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42688</th>\n",
       "      <td>2.846232e-10</td>\n",
       "      <td>1.342760e-11</td>\n",
       "      <td>3.760796e-12</td>\n",
       "      <td>3.510913e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42689</th>\n",
       "      <td>9.707442e-10</td>\n",
       "      <td>2.485227e-11</td>\n",
       "      <td>6.117589e-12</td>\n",
       "      <td>8.264715e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42690</th>\n",
       "      <td>1.084597e-09</td>\n",
       "      <td>1.266863e-10</td>\n",
       "      <td>2.847203e-11</td>\n",
       "      <td>9.301527e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42691 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              delta         theta         alpha          beta label  \\\n",
       "0      6.160646e-12  3.309411e-12  1.943593e-12  2.366059e-12  Wake   \n",
       "1      4.988774e-10  1.235113e-11  4.446865e-12  2.844799e-12  Wake   \n",
       "2      1.534984e-10  2.390680e-12  1.519197e-12  5.406593e-13  Wake   \n",
       "3      4.962507e-11  2.943184e-12  1.687577e-12  5.375286e-13  Wake   \n",
       "4      2.378089e-11  1.779550e-12  2.156748e-12  4.648331e-13  Wake   \n",
       "...             ...           ...           ...           ...   ...   \n",
       "42686  4.120337e-11  7.154511e-12  1.723270e-12  2.457063e-13    N2   \n",
       "42687  9.937038e-11  4.455668e-12  1.793157e-12  3.096157e-13    N2   \n",
       "42688  2.846232e-10  1.342760e-11  3.760796e-12  3.510913e-12  Wake   \n",
       "42689  9.707442e-10  2.485227e-11  6.117589e-12  8.264715e-12  Wake   \n",
       "42690  1.084597e-09  1.266863e-10  2.847203e-11  9.301527e-12  Wake   \n",
       "\n",
       "      subject_id  cycle  \n",
       "0           7011      0  \n",
       "1           7011      0  \n",
       "2           7011      0  \n",
       "3           7011      0  \n",
       "4           7011      0  \n",
       "...          ...    ...  \n",
       "42686       7242      4  \n",
       "42687       7242      4  \n",
       "42688       7242      4  \n",
       "42689       7242      4  \n",
       "42690       7242      4  \n",
       "\n",
       "[42691 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edf.to_csv('../data/eeg_hypno.csv', index=False)\n",
    "\n",
    "df_edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            delta         theta         alpha          beta label  subject_id  \\\n",
       " 436  6.000278e-12  4.165632e-12  1.518577e-12  5.389868e-13    N1        7011   \n",
       " 437  4.100465e-11  1.412482e-11  2.410052e-12  6.361563e-13    N2        7011   \n",
       " 438  4.552100e-11  9.505402e-12  1.668170e-12  6.958425e-13    N2        7011   \n",
       " 439  4.580635e-11  6.770875e-12  2.308565e-12  4.922427e-13    N2        7011   \n",
       " 440  2.434543e-11  8.388278e-12  2.216716e-12  1.233108e-12    N2        7011   \n",
       " 441  1.458869e-10  5.686859e-12  2.762954e-12  2.125304e-12  Wake        7011   \n",
       " 442  1.236373e-09  4.155885e-11  6.151850e-12  4.496759e-12  Wake        7011   \n",
       " 443  4.436090e-10  3.212341e-11  2.944308e-12  8.002102e-13  Wake        7011   \n",
       " 444  7.205938e-10  1.410224e-11  1.812339e-12  1.367909e-12  Wake        7011   \n",
       " 445  5.507296e-10  7.683485e-12  2.604376e-12  6.220623e-13  Wake        7011   \n",
       " 446  2.907716e-10  1.667144e-11  3.947145e-12  1.027118e-12  Wake        7011   \n",
       " 447  2.319915e-11  4.251946e-12  2.334408e-12  4.168527e-13  Wake        7011   \n",
       " 448  4.986561e-11  4.588360e-12  1.599443e-12  5.027828e-13  Wake        7011   \n",
       " 449  1.351745e-10  7.261009e-12  1.673878e-12  9.605170e-13  Wake        7011   \n",
       " 450  5.985399e-12  2.087897e-12  2.058931e-12  4.766839e-13  Wake        7011   \n",
       " 451  5.503219e-12  4.364378e-12  8.974958e-13  4.129937e-13  Wake        7011   \n",
       " 452  4.277928e-12  8.133782e-12  1.300800e-12  6.172261e-13    N1        7011   \n",
       " 453  8.927210e-12  1.181730e-11  1.197318e-12  7.343688e-13    N1        7011   \n",
       " 454  2.994278e-11  7.816666e-12  9.983545e-13  8.565990e-13    N1        7011   \n",
       " 455  9.018121e-11  1.137448e-11  2.261551e-12  6.656171e-13    N2        7011   \n",
       " \n",
       "      cycle  cycle_change  \n",
       " 436      3          True  \n",
       " 437      3         False  \n",
       " 438      3         False  \n",
       " 439      3         False  \n",
       " 440      3         False  \n",
       " 441      3         False  \n",
       " 442      3         False  \n",
       " 443      3         False  \n",
       " 444      3         False  \n",
       " 445      3         False  \n",
       " 446      3         False  \n",
       " 447      3         False  \n",
       " 448      3         False  \n",
       " 449      3         False  \n",
       " 450      3         False  \n",
       " 451      3         False  \n",
       " 452      3         False  \n",
       " 453      3         False  \n",
       " 454      3         False  \n",
       " 455      3         False  ,\n",
       " cycle\n",
       " 0    163\n",
       " 1    135\n",
       " 2    138\n",
       " 3    656\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 12    27\n",
       " 2     24\n",
       " 4     14\n",
       " 6      8\n",
       " 10     8\n",
       " 8      7\n",
       " 5      0\n",
       " 1      0\n",
       " 3      0\n",
       " 9      0\n",
       " Name: label, dtype: int64,\n",
       " np.int64(436))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the updated CSV file\n",
    "df = pd.read_csv('../data/eeg_hypno.csv')\n",
    "\n",
    "# Filter for subject 7011\n",
    "subject_7011 = df[df['subject_id'] == 7011].reset_index(drop=True)\n",
    "\n",
    "# Check the value counts of cycle column to get cycle distribution\n",
    "cycle_distribution = subject_7011['cycle'].value_counts().sort_index()\n",
    "\n",
    "# Check where cycle transitions occur\n",
    "subject_7011['cycle_change'] = subject_7011['cycle'].diff().fillna(0).ne(0)\n",
    "\n",
    "# Focus on the problematic section from cycle 3 onward\n",
    "after_cycle_3 = subject_7011[subject_7011['cycle'] >= 3]\n",
    "\n",
    "# Count REMs within the problematic area\n",
    "rem_streaks = after_cycle_3['label'].eq('REM').astype(int)\n",
    "\n",
    "# Check longest REM streak within the cycle >= 3 zone\n",
    "rem_streak_lengths = rem_streaks.groupby(rem_streaks.ne(rem_streaks.shift()).cumsum()).sum()\n",
    "\n",
    "after_cycle_3_start_index = subject_7011[subject_7011['cycle'] == 3].index[0]\n",
    "\n",
    "(after_cycle_3.head(20), cycle_distribution, rem_streak_lengths.sort_values(ascending=False).head(10), after_cycle_3_start_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickload through the .csv\n",
    "Skip to here to avoid generating files for the thousanth time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.160000e-12</td>\n",
       "      <td>3.310000e-12</td>\n",
       "      <td>1.940000e-12</td>\n",
       "      <td>2.370000e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.990000e-10</td>\n",
       "      <td>1.240000e-11</td>\n",
       "      <td>4.450000e-12</td>\n",
       "      <td>2.840000e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.530000e-10</td>\n",
       "      <td>2.390000e-12</td>\n",
       "      <td>1.520000e-12</td>\n",
       "      <td>5.410000e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.960000e-11</td>\n",
       "      <td>2.940000e-12</td>\n",
       "      <td>1.690000e-12</td>\n",
       "      <td>5.380000e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.380000e-11</td>\n",
       "      <td>1.780000e-12</td>\n",
       "      <td>2.160000e-12</td>\n",
       "      <td>4.650000e-13</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42686</th>\n",
       "      <td>4.120000e-11</td>\n",
       "      <td>7.150000e-12</td>\n",
       "      <td>1.720000e-12</td>\n",
       "      <td>2.460000e-13</td>\n",
       "      <td>N2</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42687</th>\n",
       "      <td>9.940000e-11</td>\n",
       "      <td>4.460000e-12</td>\n",
       "      <td>1.790000e-12</td>\n",
       "      <td>3.100000e-13</td>\n",
       "      <td>N2</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42688</th>\n",
       "      <td>2.850000e-10</td>\n",
       "      <td>1.340000e-11</td>\n",
       "      <td>3.760000e-12</td>\n",
       "      <td>3.510000e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42689</th>\n",
       "      <td>9.710000e-10</td>\n",
       "      <td>2.490000e-11</td>\n",
       "      <td>6.120000e-12</td>\n",
       "      <td>8.260000e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42690</th>\n",
       "      <td>1.080000e-09</td>\n",
       "      <td>1.270000e-10</td>\n",
       "      <td>2.850000e-11</td>\n",
       "      <td>9.300000e-12</td>\n",
       "      <td>Wake</td>\n",
       "      <td>7242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42691 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              delta         theta         alpha          beta label  \\\n",
       "0      6.160000e-12  3.310000e-12  1.940000e-12  2.370000e-12  Wake   \n",
       "1      4.990000e-10  1.240000e-11  4.450000e-12  2.840000e-12  Wake   \n",
       "2      1.530000e-10  2.390000e-12  1.520000e-12  5.410000e-13  Wake   \n",
       "3      4.960000e-11  2.940000e-12  1.690000e-12  5.380000e-13  Wake   \n",
       "4      2.380000e-11  1.780000e-12  2.160000e-12  4.650000e-13  Wake   \n",
       "...             ...           ...           ...           ...   ...   \n",
       "42686  4.120000e-11  7.150000e-12  1.720000e-12  2.460000e-13    N2   \n",
       "42687  9.940000e-11  4.460000e-12  1.790000e-12  3.100000e-13    N2   \n",
       "42688  2.850000e-10  1.340000e-11  3.760000e-12  3.510000e-12  Wake   \n",
       "42689  9.710000e-10  2.490000e-11  6.120000e-12  8.260000e-12  Wake   \n",
       "42690  1.080000e-09  1.270000e-10  2.850000e-11  9.300000e-12  Wake   \n",
       "\n",
       "       subject_id  cycle  \n",
       "0            7011      0  \n",
       "1            7011      0  \n",
       "2            7011      0  \n",
       "3            7011      0  \n",
       "4            7011      0  \n",
       "...           ...    ...  \n",
       "42686        7242      4  \n",
       "42687        7242      4  \n",
       "42688        7242      4  \n",
       "42689        7242      4  \n",
       "42690        7242      4  \n",
       "\n",
       "[42691 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_edf = pd.read_csv('../data/eeg_hypno.csv')\n",
    "df_edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Basic Classifier (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.56      0.31      0.40       731\n",
      "          N2       0.78      0.90      0.84      3970\n",
      "          N3       0.85      0.82      0.83      1283\n",
      "         REM       0.79      0.73      0.76      1670\n",
      "        Wake       0.78      0.68      0.73       885\n",
      "\n",
      "    accuracy                           0.78      8539\n",
      "   macro avg       0.75      0.69      0.71      8539\n",
      "weighted avg       0.77      0.78      0.77      8539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "X = df_edf.drop(columns=['label'])\n",
    "y = df_edf['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=10)\n",
    "\n",
    "base_rf = RandomForestClassifier(n_estimators=100, random_state=10, class_weight='balanced')\n",
    "base_rf.fit(X_train, y_train) \n",
    "\n",
    "y_pred = base_rf.predict(X_test) \n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Project Adapted to Waveforms (LONG WAIT, HYPERPARAM TUNING):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sampled 28816 rows (90.0%)\n",
      "Class distribution:\n",
      "1    13399\n",
      "3     5636\n",
      "2     4330\n",
      "4     2985\n",
      "0     2466\n",
      "============================================================ \n",
      "\n",
      "Starting Grand Tuner | CV: 5 | Scoring: accuracy\n",
      "Model: RandomForestClassifier | SMOTE: True | Random Iterations: 20\n",
      "============================================================ \n",
      "\n",
      "**RandomForestClassifier param grid is None, using default\n",
      "\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "‚è±Ô∏è RandomizedSearchCV completed in 4.82 minutes\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "‚è±Ô∏è GridSearchCV completed in 3.61 minutes\n",
      "\n",
      "==================================================\n",
      "üèÜ Best Hyperparameters: {\n",
      "  \"classifier__n_estimators\": 200,\n",
      "  \"classifier__min_samples_split\": 5,\n",
      "  \"classifier__min_samples_leaf\": 1,\n",
      "  \"classifier__max_features\": \"log2\",\n",
      "  \"classifier__max_depth\": null\n",
      "}\n",
      "\n",
      "üìä Best accuracy: 0.7620\n",
      "üíæ Saved best params for RandomForestClassifier to ../tuned_params\\RandomForestClassifier_best_params.json\n",
      "\n",
      "============================================================ \n",
      "\n",
      "[TRAINING] Starting model training...\n",
      "\n",
      "‚Üí Training RandomForest with params:\n",
      "{\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"classifier__n_estimators\": 200,\n",
      "    \"classifier__min_samples_split\": 5,\n",
      "    \"classifier__min_samples_leaf\": 1,\n",
      "    \"classifier__max_features\": \"log2\",\n",
      "    \"classifier__max_depth\": null\n",
      "}\n",
      "\n",
      "‚úÖ RandomForest trained | Saved to ../models\\RandomForest.pkl\n",
      "============================================================\n",
      "\n",
      " Running evaluation on test set...\n",
      "‚ö†Ô∏è Imbalanced test set detected (Minority class = 8.55%)\n",
      "\n",
      "Label decoder active:\n",
      "  y_test unique: [0 1 2 3 4]\n",
      "  Classes: ['N1' 'N2' 'N3' 'REM' 'Wake']\n",
      "\n",
      "Evaluating Model: RandomForestClassifier\n",
      "Hyperparameters:\n",
      "{\n",
      "    \"bootstrap\": true,\n",
      "    \"ccp_alpha\": 0.0,\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"criterion\": \"gini\",\n",
      "    \"max_depth\": null,\n",
      "    \"max_features\": \"log2\",\n",
      "    \"max_leaf_nodes\": null,\n",
      "    \"max_samples\": null,\n",
      "    \"min_impurity_decrease\": 0.0,\n",
      "    \"min_samples_leaf\": 1,\n",
      "    \"min_samples_split\": 5,\n",
      "    \"min_weight_fraction_leaf\": 0.0,\n",
      "    \"monotonic_cst\": null,\n",
      "    \"n_estimators\": 200,\n",
      "    \"n_jobs\": null,\n",
      "    \"oob_score\": false,\n",
      "    \"random_state\": null,\n",
      "    \"verbose\": 0,\n",
      "    \"warm_start\": false\n",
      "}\n",
      "\n",
      "Overall Metrics:\n",
      "| Metric             |   Score |\n",
      "|:-------------------|--------:|\n",
      "| Accuracy           |  0.779  |\n",
      "| Weighted Precision |  0.7712 |\n",
      "| Weighted Recall    |  0.779  |\n",
      "| Weighted F1-Score  |  0.7737 |\n",
      "\n",
      "Class-Specific Metrics:\n",
      "| Class   |   Precision |   Recall |   F1-Score |   Support |\n",
      "|:--------|------------:|---------:|-----------:|----------:|\n",
      "| N1      |      0.4993 |   0.3647 |     0.4215 |       913 |\n",
      "| N2      |      0.812  |   0.861  |     0.8358 |      4963 |\n",
      "| N3      |      0.8183 |   0.8535 |     0.8355 |      1604 |\n",
      "| REM     |      0.7775 |   0.7417 |     0.7592 |      2087 |\n",
      "| Wake    |      0.7324 |   0.7152 |     0.7237 |      1106 |\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.run_pipeline import tune_and_train_full\n",
    "\n",
    "# Label Encoding with decoding built into tune_and_train_full()\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, stratify=y_encoded, random_state=10)\n",
    "\n",
    "rf_wave, best_params = tune_and_train_full(RandomForestClassifier, \n",
    "                    'RandomForest', \n",
    "                    X_train, \n",
    "                    y_train,\n",
    "                    X_test=X_test, \n",
    "                    y_test=y_test, \n",
    "                    model_params={'class_weight': 'balanced'},\n",
    "                    sample_frac=0.9, \n",
    "                    scoring='accuracy',\n",
    "                    label_encoder=le) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label decoder active:\n",
      "  y_test unique: [0 1 2 3 4]\n",
      "  Classes: ['N1' 'N2' 'N3' 'REM' 'Wake']\n",
      "\n",
      "Evaluating Model: RandomForestClassifier\n",
      "Hyperparameters:\n",
      "{\n",
      "    \"bootstrap\": true,\n",
      "    \"ccp_alpha\": 0.0,\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"criterion\": \"gini\",\n",
      "    \"max_depth\": null,\n",
      "    \"max_features\": \"log2\",\n",
      "    \"max_leaf_nodes\": null,\n",
      "    \"max_samples\": null,\n",
      "    \"min_impurity_decrease\": 0.0,\n",
      "    \"min_samples_leaf\": 1,\n",
      "    \"min_samples_split\": 5,\n",
      "    \"min_weight_fraction_leaf\": 0.0,\n",
      "    \"monotonic_cst\": null,\n",
      "    \"n_estimators\": 200,\n",
      "    \"n_jobs\": null,\n",
      "    \"oob_score\": false,\n",
      "    \"random_state\": null,\n",
      "    \"verbose\": 0,\n",
      "    \"warm_start\": false\n",
      "}\n",
      "\n",
      "Overall Metrics:\n",
      "| Metric             |   Score |\n",
      "|:-------------------|--------:|\n",
      "| Accuracy           |  0.779  |\n",
      "| Weighted Precision |  0.7712 |\n",
      "| Weighted Recall    |  0.779  |\n",
      "| Weighted F1-Score  |  0.7737 |\n",
      "\n",
      "Class-Specific Metrics:\n",
      "| Class   |   Precision |   Recall |   F1-Score |   Support |\n",
      "|:--------|------------:|---------:|-----------:|----------:|\n",
      "| N1      |      0.4993 |   0.3647 |     0.4215 |       913 |\n",
      "| N2      |      0.812  |   0.861  |     0.8358 |      4963 |\n",
      "| N3      |      0.8183 |   0.8535 |     0.8355 |      1604 |\n",
      "| REM     |      0.7775 |   0.7417 |     0.7592 |      2087 |\n",
      "| Wake    |      0.7324 |   0.7152 |     0.7237 |      1106 |\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.eval import eval_classification \n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # y is label column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, stratify=y_encoded, random_state=10)\n",
    "\n",
    "rf_pipeline = joblib.load('../models/RandomForest.pkl')\n",
    "\n",
    "eval_classification(rf_pipeline, X_test, y_test, label_encoder=le) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great, Classifier is Built! What Now?\n",
    "Just completed work on a sleep stage classifier that is ~60% effective. While that's not bad... we can do better, by using the elements of the data to our advantage: \n",
    "- Sleep is **not** random, it follows structured stage transitions\n",
    "- HMM can capture those structured transitions as probabilities\n",
    "- We can use a HMM approach to smooth the pipeline model's predictions into a more biologically probably sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While Discussing Goals: \n",
    "**Real-time sleep classification**. It's possible (with a ton of work). That is our final product. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Reality: HMM Smoothing Pass \n",
    "\n",
    "It's important to remember that the HMM is *not* making new predictions or replacing the already nicely trained and optimized classifier. The HMM will function to refine the outputs.  \n",
    "  \n",
    "We'll learn from the data in order to estimate stage transition probabilities. For example: how likely are you to stay in N2, or jump to N3, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "def apply_hybrid_hmm(df: pd.DataFrame, base_predictions, label_encoder, transition_matrices): \n",
    "    '''\n",
    "    Applies hybrid GaussianHMM smoothing to predicted labels using per-cycle transition matrices\n",
    "\n",
    "    Args: \n",
    "        df (pd.DataFrame): EEG data with 'cycle' and 'subject_id' cols\n",
    "        base_predictions (np.ndarray): Raw model predictions (same order as df) \n",
    "        label_encoder (LabelEncoder): Fitted encoder to convert betweeen stages labels and indices\n",
    "        transition_matrices (dict): \n",
    "            Keys= 'early', 'mid', 'late'\n",
    "            Values= 2D np.ndarray (5x5 transitions)\n",
    "\n",
    "    Returns: \n",
    "        np.ndarray: smoothed predictions using cycle-aware HMM pass-over \n",
    "    '''\n",
    "\n",
    "    df = df.copy()\n",
    "    df['pred'] = base_predictions\n",
    "\n",
    "    stage_order = label_encoder.classes_\n",
    "    n_states = len(stage_order) \n",
    "\n",
    "    smoothed_all = []\n",
    "\n",
    "    for (subject_id, cycle), group in df.groupby(['subject_id', 'cycle']): \n",
    "        cycle_len = len(group) \n",
    "        X = group[['delta', 'theta', 'alpha', 'beta']].values\n",
    "        y_pred_idx = label_encoder.transform(group['pred']) \n",
    "\n",
    "        # Select transition matrix based on cycle phase\n",
    "        if cycle <= 1: \n",
    "            phase = 'early'\n",
    "        elif cycle <= 3:\n",
    "            phase = 'mid'\n",
    "        else: \n",
    "            phase = 'late'\n",
    "\n",
    "        transmat = transition_matrices[phase] \n",
    "\n",
    "        hmm_model = GaussianHMM(n_components=n_states, covariance_type='full', n_iter=100)\n",
    "        hmm_model.transmat_ = transmat\n",
    "\n",
    "        # Assigning heavy bias (95%) toward starting in Wake\n",
    "        startprob = np.full(n_states, 0.01)\n",
    "        startprob[label_encoder.transform(['Wake'])[0]] = 0.95\n",
    "\n",
    "        hmm_model.startprob_ = startprob / startprob.sum()\n",
    "\n",
    "        # Fit only the Guassian part: \n",
    "        hmm_model.fit(X)\n",
    "\n",
    "        smoothed_idx = hmm_model.predict(X)\n",
    "        smoothed_labels = label_encoder.inverse_transform(smoothed_idx) \n",
    "\n",
    "        smoothed_all.extend(smoothed_labels) \n",
    "\n",
    "    return np.array(smoothed_all) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Order: ['N1', 'N2', 'N3', 'REM', 'Wake']\n",
    "transition_matrices = {\n",
    "    \"early\": np.array([\n",
    "        [0.10, 0.85, 0.00, 0.00, 0.05],  # N1 ‚Üí mostly N2\n",
    "        [0.00, 0.80, 0.15, 0.00, 0.05],  # N2 ‚Üí N3\n",
    "        [0.00, 0.30, 0.65, 0.00, 0.05],  # N3 ‚Üí N2\n",
    "        [0.00, 0.00, 0.00, 0.90, 0.10],  # REM ‚Üí Wake\n",
    "        [0.40, 0.50, 0.00, 0.00, 0.10],  # Wake ‚Üí N1/N2\n",
    "    ]),\n",
    "\n",
    "    \"mid\": np.array([\n",
    "        [0.10, 0.85, 0.00, 0.00, 0.05],\n",
    "        [0.05, 0.75, 0.10, 0.05, 0.05],\n",
    "        [0.05, 0.30, 0.60, 0.00, 0.05],\n",
    "        [0.00, 0.10, 0.00, 0.80, 0.10],\n",
    "        [0.30, 0.60, 0.00, 0.00, 0.10],\n",
    "    ]),\n",
    "\n",
    "    \"late\": np.array([\n",
    "        [0.10, 0.80, 0.00, 0.05, 0.05],\n",
    "        [0.10, 0.65, 0.00, 0.15, 0.10],\n",
    "        [0.10, 0.20, 0.50, 0.00, 0.20],\n",
    "        [0.05, 0.15, 0.00, 0.75, 0.05],\n",
    "        [0.20, 0.65, 0.00, 0.10, 0.05],\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'covars' must be symmetric, positive-definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\stats.py:81\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[1;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     cv_chol \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# The model is most probably stuck in a component with too\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# few observations, we need to reinitialize this components\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:101\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mCompute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m c, lower \u001b[38;5;241m=\u001b[39m \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:38\u001b[0m, in \u001b[0;36m_cholesky\u001b[1;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th leading minor of the array is not positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m info)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 3-th leading minor of the array is not positive definite",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\stats.py:86\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[1;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     cv_chol \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_covar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:101\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mCompute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m c, lower \u001b[38;5;241m=\u001b[39m \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:38\u001b[0m, in \u001b[0;36m_cholesky\u001b[1;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th leading minor of the array is not positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m info)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 3-th leading minor of the array is not positive definite",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m base_predictions \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39minverse_transform(rf_pipeline\u001b[38;5;241m.\u001b[39mpredict(X))\n\u001b[1;32m----> 3\u001b[0m smoothed_preds \u001b[38;5;241m=\u001b[39m \u001b[43mapply_hybrid_hmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_edf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition_matrices\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 52\u001b[0m, in \u001b[0;36mapply_hybrid_hmm\u001b[1;34m(df, base_predictions, label_encoder, transition_matrices)\u001b[0m\n\u001b[0;32m     49\u001b[0m hmm_model\u001b[38;5;241m.\u001b[39mstartprob_ \u001b[38;5;241m=\u001b[39m startprob \u001b[38;5;241m/\u001b[39m startprob\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Fit only the Guassian part: \u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mhmm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m smoothed_idx \u001b[38;5;241m=\u001b[39m hmm_model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     55\u001b[0m smoothed_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(smoothed_idx) \n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\base.py:485\u001b[0m, in \u001b[0;36m_AbstractHMM.fit\u001b[1;34m(self, X, lengths)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter):\n\u001b[1;32m--> 485\u001b[0m     stats, curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# Compute lower bound before updating model parameters\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(curr_logprob)\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\base.py:764\u001b[0m, in \u001b[0;36m_AbstractHMM._do_estep\u001b[1;34m(self, X, lengths)\u001b[0m\n\u001b[0;32m    762\u001b[0m curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_X \u001b[38;5;129;01min\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39msplit_X_lengths(X, lengths):\n\u001b[1;32m--> 764\u001b[0m     lattice, logprob, posteriors, fwdlattice, bwdlattice \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;66;03m# Derived HMM classes will implement the following method to\u001b[39;00m\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# update their probability distributions, so keep\u001b[39;00m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;66;03m# a single call to this method for simplicity.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_sufficient_statistics(\n\u001b[0;32m    769\u001b[0m         stats, sub_X, lattice, posteriors, fwdlattice,\n\u001b[0;32m    770\u001b[0m         bwdlattice)\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\base.py:883\u001b[0m, in \u001b[0;36mBaseHMM._fit_log\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 883\u001b[0m     log_frameprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m     log_prob, fwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mforward_log(\n\u001b[0;32m    885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n\u001b[0;32m    886\u001b[0m     bwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mbackward_log(\n\u001b[0;32m    887\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\_emissions.py:130\u001b[0m, in \u001b[0;36mBaseGaussianHMM._compute_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_log_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_multivariate_normal_density\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_covars_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\stats.py:42\u001b[0m, in \u001b[0;36mlog_multivariate_normal_density\u001b[1;34m(X, means, covars, covariance_type)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mCompute the log probability under a multivariate Gaussian distribution.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    X under each of the n_components multivariate Gaussian distributions.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m log_multivariate_normal_density_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspherical\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_spherical,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtied\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_tied,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_diag,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_full}\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_multivariate_normal_density_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcovariance_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovars\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Desktop\\Code_Projects\\.venv\\Lib\\site-packages\\hmmlearn\\stats.py:89\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[1;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[0;32m     86\u001b[0m         cv_chol \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mcholesky(cv \u001b[38;5;241m+\u001b[39m min_covar \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(nf),\n\u001b[0;32m     87\u001b[0m                                   lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcovars\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be symmetric, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive-definite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m cv_log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mdiagonal(cv_chol)))\n\u001b[0;32m     93\u001b[0m cv_sol \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39msolve_triangular(cv_chol, (X \u001b[38;5;241m-\u001b[39m mu)\u001b[38;5;241m.\u001b[39mT, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mValueError\u001b[0m: 'covars' must be symmetric, positive-definite"
     ]
    }
   ],
   "source": [
    "base_predictions = le.inverse_transform(rf_pipeline.predict(X))\n",
    "\n",
    "smoothed_preds = apply_hybrid_hmm(df_edf, base_predictions, le, transition_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. \n",
    "# Convert predicted and true labels back to class indices\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_test_decoded = le.inverse_transform(y_test) \n",
    "y_pred_decoded = le.inverse_transform(rf_wave.predict(X_test)) \n",
    "\n",
    "# Re-encode with a fresh label encoder for HMM\n",
    "le_hmm = LabelEncoder()\n",
    "y_test_idx = le_hmm.fit_transform(y_test_decoded)\n",
    "y_pred_idx = le_hmm.fit_transform(y_pred_decoded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.\n",
    "# Fit the HMM (only on stage transitions)\n",
    "\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "\n",
    "n_states = len(le_hmm.classes_) \n",
    "model_hmm = hmm.GaussianHMM(n_components=5, covariance_type='full', n_iter=100)\n",
    "\n",
    "# Now reshape to (n_samples, 1)-- required by hmmlearn\n",
    "y_test_seq = y_test_idx.reshape(-1, 1) \n",
    "\n",
    "# Fit transition and start probs using the true label seq\n",
    "model_hmm.fit(y_test_seq) \n",
    "\n",
    "# Define domain-informed transition matrix (Wake, N1, N2, N3, REM)\n",
    "custom_transitions = np.array([\n",
    "    [0.1,  0.8,  0.05, 0.0,  0.05],  # Wake -> mostly N1\n",
    "    [0.0,  0.1,  0.8,  0.1,  0.0],  # N1 -> mostly N2\n",
    "    [0.0,  0.1,  0.2,  0.6,  0.1],  # N2 -> transition to N3\n",
    "    [0.0,  0.0,  0.4,  0.3,  0.3],  # N3 -> some REM or back to N2\n",
    "    [0.2,  0.3,  0.3,  0.0,  0.2],  # REM -> looping back, or staying REM\n",
    "])\n",
    "\n",
    "# Normalize to ensure each row sums to 1\n",
    "custom_transitions = custom_transitions / custom_transitions.sum(axis=1, keepdims=True)\n",
    "custom_transitions\n",
    "\n",
    "model_hmm.transmat_ = custom_transitions\n",
    "model_hmm.startprob_ = np.array([0.6, 0.4, 0.0, 0.0, 0.0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. \n",
    "# Use Classifier preds + HMM for smoothing\n",
    "\n",
    "# Classifier pred sequence (unsmoothed) \n",
    "y_pred_seq = y_pred_idx.reshape(-1, 1) \n",
    "\n",
    "# Applying Viterbi to get smoothed predictions\n",
    "smoothed_idx = model_hmm.predict(y_pred_seq) \n",
    "\n",
    "# Decode to original class labels\n",
    "smoothed_labels = le_hmm.inverse_transform(smoothed_idx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things more clear, we now have: \n",
    "- `y_test_decoded` -- ground truth\n",
    "- `y_pred_decoded` -- raw classifier \n",
    "- `smoothed_labels` -- post-HMM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Classifier (Raw) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.60      0.55      0.58       337\n",
      "          N2       0.56      0.59      0.58       449\n",
      "          N3       0.74      0.81      0.77       432\n",
      "         REM       0.62      0.50      0.55        98\n",
      "        Wake       0.62      0.57      0.59       191\n",
      "\n",
      "    accuracy                           0.64      1507\n",
      "   macro avg       0.63      0.60      0.61      1507\n",
      "weighted avg       0.63      0.64      0.63      1507\n",
      "\n",
      "üß† HMM-Smooth Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.58      0.47      0.52       337\n",
      "          N2       0.12      0.04      0.06       449\n",
      "          N3       0.14      0.15      0.15       432\n",
      "         REM       0.28      0.38      0.32        98\n",
      "        Wake       0.03      0.08      0.05       191\n",
      "\n",
      "    accuracy                           0.20      1507\n",
      "   macro avg       0.23      0.22      0.22      1507\n",
      "weighted avg       0.23      0.20      0.20      1507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4. \n",
    "# Evaluate Improvements\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"üîç Classifier (Raw) Performance:\")\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))\n",
    "\n",
    "print(\"üß† HMM-Smooth Performance:\")\n",
    "print(classification_report(y_test_decoded, smoothed_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving things here for tonight, tomorrow *morning* come back to create and work on the visualization code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "def plot_sleep_sequences(y_true, y_pred, y_hmm, label_order=None): \n",
    "    '''\n",
    "    Simultaneously Plots: \n",
    "        1) ground truth\n",
    "        2) classifier preds\n",
    "        3) HMM-smoothed preds over time\n",
    "\n",
    "    Args: \n",
    "        y_true (array-like): Ground truth labels\n",
    "        y_preds (array-like): Classifier raw predictions\n",
    "        y_hmm (array-like): HMM-smoothed predictions\n",
    "        label_order (list): Optional, ordered list of sleep stage names for consistent y-axis\n",
    "    '''\n",
    "\n",
    "    # Align stage names to consistent int-encoding\n",
    "    if label_order is None: \n",
    "        label_order = sorted(list(set(y_true) | set(y_pred) | set(y_hmm)))\n",
    "\n",
    "    label_to_int = {label: i for i, label in enumerate(label_order)} \n",
    "\n",
    "    y_true_idx = [label_to_int[y] for y in y_true]\n",
    "    y_pred_idx = [label_to_int[y] for y in y_pred]\n",
    "    y_hmm_idx = [label_to_int[y] for y in y_hmm] \n",
    "\n",
    "    data = np.array([y_true_idx, y_pred_idx, y_hmm_idx]) \n",
    "\n",
    "    # Define colors for 5 stages\n",
    "    stage_colors = {\n",
    "        \"Wake\": \"#1f77b4\",   # blue\n",
    "        \"N1\": \"#ff7f0e\",     # orange\n",
    "        \"N2\": \"#2ca02c\",     # green\n",
    "        \"N3\": \"#d62728\",     # red\n",
    "        \"REM\": \"#9467bd\"     # purple\n",
    "    }\n",
    "\n",
    "    # Colourmap and listing colours in stage order\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    cmap = ListedColormap([stage_colors[stage] for stage in label_order]) \n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(16,3))\n",
    "    plt.imshow(data, aspect='auto', cmap=cmap, interpolation='nearest')\n",
    "\n",
    "    plt.yticks([0, 1, 2], ['Ground Truth', 'Classifier', 'HMM Smoothed'])\n",
    "    plt.xticks([])  # too many to be readable\n",
    "    plt.title('Sleep Stage Sequences')\n",
    "\n",
    "    # Custom legend\n",
    "    handles = [plt.Line2D([0], [0], color=stage_colors[stage], lw=6) for stage in label_order]\n",
    "    plt.legend(handles, label_order, bbox_to_anchor=(1.01, 1), loc='upper left', title=\"Stages\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_decoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plot_sleep_sequences(\n\u001b[1;32m----> 2\u001b[0m     y_true\u001b[38;5;241m=\u001b[39m\u001b[43my_test_decoded\u001b[49m[:\u001b[38;5;241m50\u001b[39m],     \u001b[38;5;66;03m# First ~50 minutes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39my_pred_decoded[:\u001b[38;5;241m50\u001b[39m],\n\u001b[0;32m      4\u001b[0m     y_hmm\u001b[38;5;241m=\u001b[39msmoothed_labels[:\u001b[38;5;241m50\u001b[39m],\n\u001b[0;32m      5\u001b[0m     label_order\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWake\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_decoded' is not defined"
     ]
    }
   ],
   "source": [
    "plot_sleep_sequences(\n",
    "    y_true=y_test_decoded[:50],     # First ~50 minutes\n",
    "    y_pred=y_pred_decoded[:50],\n",
    "    y_hmm=smoothed_labels[:50],\n",
    "    label_order=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation, Not Rollback\n",
    "Since smushing together ~41 eeg and hypnogram pairs (for the purpose of a large enough training sample), I've realized that this many different Cycles (complicated by Cycle 1 != Cycle 2) are present, and all mashed together as if it's 6000 hours of constant sleep.  \n",
    "  \n",
    "However, it makes sense why I had to do it. Now, in order to preserve the **temporal structure**, we're going to: \n",
    "1) Track sleep cycles explicitly\n",
    "2) Add a `cycle_number` feature \n",
    "3) Test HMM-Smoothing on a per-night and per-cycle basis\n",
    "\n",
    "If none of these options work, RNN or a Temportal CNN might be a better fit for the nature of our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
